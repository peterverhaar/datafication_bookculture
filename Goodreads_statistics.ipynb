{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec6baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import os\n",
    "from os.path import join\n",
    "import stanza\n",
    "import re\n",
    "from collections import Counter\n",
    "from langdetect import detect\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "ana = SentimentIntensityAnalyzer()\n",
    "import requests\n",
    "from langdetect import detect\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize,pos_tag\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from bs4.element import Comment\n",
    "# import credentials\n",
    "# key = credentials.key\n",
    "import xml.etree.ElementTree as ET\n",
    "import string\n",
    "\n",
    "punctuation_marks = [char for char in string.punctuation]\n",
    "\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list = stopwords.words('english')\n",
    "for mark in string.punctuation + '“”’—‘':\n",
    "    stopword_list.append(mark)\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    new_list= []\n",
    "    for w in words:\n",
    "        if w.isalnum():\n",
    "            new_list.append( w )\n",
    "    return new_list\n",
    "\n",
    "def sorted_by_value( dict , ascending = True ):\n",
    "    if ascending: \n",
    "        return {k: v for k, v in sorted(dict.items(), key=lambda item: item[1])}\n",
    "    else:\n",
    "        return {k: v for k, v in reversed( sorted(dict.items(), key=lambda item: item[1]))}\n",
    "    \n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 13_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15'\n",
    "]\n",
    "\n",
    "def select_agent():\n",
    "    n=random.randint(0,len(user_agents)-1)\n",
    "    return user_agents[n]\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "api_key = 'QypW6JzQ4XfGViss1Ks4g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a210ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = []\n",
    "\n",
    "directory = 'Lists'\n",
    "files = os.listdir(directory)\n",
    "files = [file for file in files if not(re.search(r'^[.]',file))]\n",
    "\n",
    "for list in files:\n",
    "\n",
    "    path = os.path.join(directory,list)\n",
    "    df = pd.read_csv(path,sep='\\t')\n",
    "    for i,row in df.iterrows():\n",
    "        books.append( row['primary_isbn13'] )\n",
    "\n",
    "books = set(books)\n",
    "print(len(books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "\n",
    "for isbn in books: \n",
    "    print(isbn)\n",
    "    \n",
    "    data = dict()\n",
    "    \n",
    "    api_call = f'https://www.goodreads.com/book/isbn?format=xml&key={api_key}&isbn={isbn}'\n",
    "    print(api_call)\n",
    "    \n",
    "    headers = {'User-Agent': select_agent() }\n",
    "    response = requests.get( api_call,headers=headers)\n",
    "    xml_data = response.text\n",
    "    \n",
    "    tree = ET.ElementTree(ET.fromstring(xml_data))\n",
    "    \n",
    "    data['isbn'] = isbn\n",
    "    data['average_rating'] = tree.find('book/average_rating').text\n",
    "    data['ratings_count'] = tree.find('book/ratings_count').text\n",
    "    data['text_reviews_count'] = tree.find('book/text_reviews_count').text\n",
    "    \n",
    "    path = join('Goodreads_reviews',f'reviews_{isbn}.txt')\n",
    "    reviews_file = open(path,encoding='utf-8')\n",
    "\n",
    "    sum_positive = 0\n",
    "    sum_negative = 0\n",
    "    sum_compound = 0\n",
    "    \n",
    "    count_lines = 0\n",
    "    for line in reviews_file:\n",
    "        count_lines += 1\n",
    "        if re.search('^\\d*\\t',line):\n",
    "            line = re.sub('^\\d*\\t','',line).strip().lower()\n",
    "        words = word_tokenize(line)\n",
    "        words = [word for word in words if word not in punctuation_marks]\n",
    "        data['nr_tokens'] = data.get('nr_tokens',0) + len(words)\n",
    "        sentences = sent_tokenize(line)\n",
    "        data['nr_sentences'] = data.get('nr_sentences',0) + len(sentences)\n",
    "\n",
    "\n",
    "        for word in words:\n",
    "            sum_positive += ana.polarity_scores(word)['pos']\n",
    "            sum_negative += ana.polarity_scores(word)['neg']\n",
    "            sum_compound += ana.polarity_scores(word)['compound']\n",
    "\n",
    "    data['downloaded_reviews'] = count_lines\n",
    "    data['average_tokens'] = data['nr_tokens'] / data['downloaded_reviews']\n",
    "    if data['nr_tokens']>0:\n",
    "        data['positive'] = sum_positive/data['nr_tokens']\n",
    "        data['negative'] = sum_negative/data['nr_tokens']\n",
    "        data['compound'] = sum_compound/data['nr_tokens'] \n",
    "    reviews.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d1fbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(reviews)\n",
    "df.to_csv('goodreads_statistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2a49bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb0f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
